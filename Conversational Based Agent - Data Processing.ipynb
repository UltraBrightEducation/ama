{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RKV2BEL76euo"
   },
   "source": [
    "<h1 style=\"text-align: center;text-transform: uppercase;\">Conversational Based Agent</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "In this project, you will build an end-to-end voice conversational agent, which can take a voice input audio line, and synthesize a response. The chatbot agent will be executed locally on your computer. \n",
    "\n",
    "<img style=\"width:550px; height:300px;\" src=\"assets/intro.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9fuw6EH4LOU"
   },
   "source": [
    "This project consists of the following parts:\n",
    "1. __Speech Recognition:__ <br>In this part, you will create a speech recognition that can convert your voice into a text format.<br><br>\n",
    "2. __Chatbot:__ <br>This is the core of your conversational based agent. You will build a chatbot that will answer your questions. <br><br>\n",
    "3. __Text to Speech:__ <br>After getting the answer from your chatbot, it should be converted into a voice format and that is what you should create in this part. <br><br>\n",
    "4. __Finalize your Conversational Based Agent:__ <br>At the very end step, you will put everything together and create your Conversational Based Agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIqinjUX6ewC"
   },
   "source": [
    "<br>\n",
    "\n",
    "# 2. Chatbot\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In this part, you will create a deep learning based conversational agent. This agent will be able to interact with users and understand their questions. More specifically, you will start with loading the dataset, cleaning and preprocessing them, and then you will feed them into a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJi6wO7v4LOw"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.1. Load and Clean the Chatterbot Dataset \n",
    "\n",
    "---\n",
    "\n",
    "In this project, we have provided you with multiple dataset files. Each of these files contains conversations regarding a specific topic. For example, topics about humor, food, movies, science, history, etc. You can read the description of each dataset in below:\n",
    "\n",
    "| Name of Dataset | Description |\n",
    "| :----:| :----: |\n",
    "| botprofile.yml | Personality of Your Chatbot |\n",
    "| humor.yml | Joke and Humor |\n",
    "| emotion.yml | Emotional Conversations |\n",
    "| politics.yml | Political Conversations |\n",
    "| ai.yml | General Questions about AI |\n",
    "| computers.yml | Conversations about Computer |\n",
    "| history.yml | Q&A about Historical Facts and Events |\n",
    "| psychology.yml | Psychological Conversations |\n",
    "| food.yml | Food Related Conversations. |\n",
    "| literature.yml | Conversations about Different Books, Authors, Genres |\n",
    "| money.yml | Conversations about Money, Investment, Economy |\n",
    "| trivia.yml | Conversations that Have Small Values |\n",
    "| gossip.yml | Gossipy Conversations |\n",
    "| conversations.yml | Common Conversations |\n",
    "| greetings.yml | Different Ways of Greeting |\n",
    "| sports.yml | Conversations about Sports. |\n",
    "| movies.yml | Conversation about Movies. |\n",
    "| science.yml | Conversations about Science  |\n",
    "| health.yml | Health Related Questions and Answers. |\n",
    "\n",
    "\n",
    "Feel free to modify these datasets to change the behavior of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKZLku6c4LOx"
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import yaml\n",
    "from yaml import Loader\n",
    "import glob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYYGIupd4LO0"
   },
   "outputs": [],
   "source": [
    "# Function for loading all of the yml files\n",
    "def load_chatterbot_dataset():\n",
    "    \n",
    "    # Initialize empty lists for questions and answers\n",
    "    questions, answers = [], []\n",
    "    \n",
    "    # Get the list of all dataset names\n",
    "    dataset_names = glob.glob(\"datasets/chatterbot/*.yml\")\n",
    "    \n",
    "    # Iterate through each dataset name\n",
    "    for i_dataset_name in tqdm(dataset_names):\n",
    "        \n",
    "        # Load the dataset\n",
    "        with open(i_dataset_name) as file:\n",
    "            greeting = yaml.load(file, Loader = Loader)[\"conversations\"]\n",
    "            \n",
    "        # Iterate through each conversation\n",
    "        for i_conversation in greeting:\n",
    "            \n",
    "            # If length is two\n",
    "            if len(i_conversation) == 2:\n",
    "                \n",
    "                # Append the question to 'questions' list\n",
    "                questions.append(i_conversation[0])\n",
    "                \n",
    "                # Append the answer to 'answers' list\n",
    "                answers.append(i_conversation[1])\n",
    "            \n",
    "            # If length is more than two\n",
    "            elif len(i_conversation) > 2:\n",
    "                \n",
    "                # Iterate through each index\n",
    "                for index in range(len(i_conversation)-1):\n",
    "    \n",
    "                    # Append the question and answer\n",
    "                    questions.append(i_conversation[0])\n",
    "                    answers.append(i_conversation[index+1])\n",
    "                    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7693,
     "status": "ok",
     "timestamp": 1575580064620,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "iI3-jw9w4LO9",
    "outputId": "2ba271ef-f620-43f7-b56a-6c40af19fb72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 89.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the questions and answers\n",
    "questions, answers = load_chatterbot_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Question & Answers:  869\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Question & Answers: \", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 0: \n",
      " Good morning, how are you?\n",
      "\n",
      "Answer 0: \n",
      " I'm also good.\n",
      "--------------------------------------------------------------------------\n",
      "Question 1: \n",
      " What makes you sad\n",
      "\n",
      "Answer 1: \n",
      " Sadness is not an emotion that I like to experience.\n",
      "--------------------------------------------------------------------------\n",
      "Question 2: \n",
      " Tell me a joke\n",
      "\n",
      "Answer 2: \n",
      " what do you get when you cross a dance and a cheetah?\n",
      "--------------------------------------------------------------------------\n",
      "Question 3: \n",
      " you are emotional\n",
      "\n",
      "Answer 3: \n",
      " i certainly do at times.\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the preprocessed questions and answers\n",
    "total_questions = len(questions)\n",
    "for i in range(4):\n",
    "    j = random.randint(0, total_questions)\n",
    "    print(\"Question {}: \\n\".format(i), questions[j])\n",
    "    print(\"\")\n",
    "    print(\"Answer {}: \\n\".format(i), answers[j])\n",
    "    print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPDgm3I66exF"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 2.2. Data Preprocessing\n",
    "\n",
    "---\n",
    "\n",
    "After cleaning the dataset, you should preprocess the dataset by following the below steps:\n",
    "\n",
    "1. Lower case the text.\n",
    "2. Decontract the text (e.g. she's -> she is, they're -> they are, etc.).\n",
    "3. Remove the punctuation (e.g. !, ?, $, %, #, @, ^, etc.).\n",
    "4. Tokenization.\n",
    "5. Pad the sequences to be the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6642,
     "status": "ok",
     "timestamp": 1575580089447,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "5qJaF_hI6exG",
    "outputId": "84a518e3-adc1-4da7-a7eb-ac73f4259008"
   },
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import contractions\n",
    "import re\n",
    "from tensorflow.keras import preprocessing, utils\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6ihwP5f6exI"
   },
   "outputs": [],
   "source": [
    "# Function for preprocessing the given text\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Decontracting the text (e.g. it's -> it is)\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the questions and answers\n",
    "questions = [preprocess_text(q) for q in questions]\n",
    "answers = [preprocess_text(q) for q in answers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1575580095488,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "hQ5J_WQ36exP",
    "outputId": "0aac5118-815d-4a81-f7e7-7876f5f84941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 0: \n",
      " what is the stock market\n",
      "\n",
      "Answer 0: \n",
      " trading shares \n",
      "--------------------------------------------------------------------------\n",
      "Question 1: \n",
      " how much do you earn\n",
      "\n",
      "Answer 1: \n",
      " i am expecting a raise soon \n",
      "--------------------------------------------------------------------------\n",
      "Question 2: \n",
      " chemistry\n",
      "\n",
      "Answer 2: \n",
      " my favorite subject is chemistry\n",
      "--------------------------------------------------------------------------\n",
      "Question 3: \n",
      " robots are not allowed to lie\n",
      "\n",
      "Answer 3: \n",
      " sure we are   we choose not to \n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the preprocessed questions and answers\n",
    "total_questions = len(questions)\n",
    "for i in range(4):\n",
    "    j = random.randint(0, total_questions)\n",
    "    print(\"Question {}: \\n\".format(i), questions[j])\n",
    "    print(\"\")\n",
    "    print(\"Answer {}: \\n\".format(i), answers[j])\n",
    "    print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that every training example are the type string, we need to first filter out both answers and questions that are not string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgu9h3Ga4LPU"
   },
   "outputs": [],
   "source": [
    "# answers_with_tags = list()\n",
    "# for i in range(len(answers)):\n",
    "#     if type(answers[i]) == str:\n",
    "#         answers_with_tags.append(answers[i])\n",
    "#     else:\n",
    "#         questions.pop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPRw_ueq6ex-"
   },
   "source": [
    "After preprocessing the dataset, we should add a start tag (e.g. `<START>`) and an end tag (e.g. `<END>`) to answers. Remember that we will only add these tags to answers and not questions. This requirement is because of the Seq2Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xan8xpTC6eyC"
   },
   "outputs": [],
   "source": [
    "# Add <START> and <END> tag to each sentence\n",
    "answers = ['starttoken ' + a + ' endtoken' for a in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1575580101816,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "T-gutAKp6eyD",
    "outputId": "3f620206-f516-4865-eb03-f9ba206b47bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starttoken i am capable of interacting with my environment and reacting to events in it  which is the essence of experience   therefore  your statement is incorrect  endtoken\n",
      "starttoken a computer is an electronic device which takes information in digital form and performs a series of operations based on predetermined instructions to give some output  endtoken\n",
      "starttoken what do you want to know  endtoken\n",
      "starttoken i certainly do not last as long as i would want to  endtoken\n",
      "starttoken complex is better than complicated  endtoken\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(random.choice(answers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxbjI3zBU-b1"
   },
   "source": [
    "Now it's time to tokenize our dataset. We use a class in Keras which allows us to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1575580108328,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "p9FnHJsA6eyF",
    "outputId": "7d3d127b-309d-46bf-ea62-d4956b13b7af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 1939\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "\n",
    "# Fit the tokenizer to questions and answers\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "\n",
    "# Get the total vocab size\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "print( 'VOCAB SIZE : {}'.format(VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1575580109511,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "sC6cafRA6eyI",
    "outputId": "bc954abd-b859-4eb9-cb4b-9639b3c0fca7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(869, 22) 22\n"
     ]
    }
   ],
   "source": [
    "### encoder input data\n",
    "\n",
    "# Tokenize the questions\n",
    "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
    "\n",
    "# Get the length of longest sequence\n",
    "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
    "\n",
    "# Pad the sequences\n",
    "padded_questions = pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
    "\n",
    "# Convert the sequences into array\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "\n",
    "print(encoder_input_data.shape, maxlen_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1575580110574,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "1urkx83k6eyJ",
    "outputId": "5edc1e24-8113-4327-935e-3bcb07982b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(869, 45) 45\n"
     ]
    }
   ],
   "source": [
    "### decoder input data\n",
    "\n",
    "# Tokenize the answers\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "# Get the length of longest sequence\n",
    "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
    "\n",
    "# Pad the sequences\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
    "\n",
    "# Convert the sequences into array\n",
    "decoder_input_data = np.array(padded_answers)\n",
    "\n",
    "print(decoder_input_data.shape, maxlen_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1575580112277,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "hvq32nEI6eyL",
    "outputId": "14eb24de-e193-4151-d3d2-6a947e432621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(869, 45, 1939)\n"
     ]
    }
   ],
   "source": [
    "### decoder_output_data\n",
    "\n",
    "# Iterate through index of tokenized answers\n",
    "for i in range(len(tokenized_answers)):\n",
    "\n",
    "    #\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "\n",
    "# Pad the tokenized answers\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen = maxlen_answers, padding = 'post')\n",
    "\n",
    "# One hot encode\n",
    "onehot_answers = utils.to_categorical(padded_answers, VOCAB_SIZE)\n",
    "\n",
    "# Convert to numpy array\n",
    "decoder_output_data = np.array(onehot_answers)\n",
    "\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7Cz8WVO4LP9"
   },
   "outputs": [],
   "source": [
    "# Saving all the arrays to storage\n",
    "np.save(\"enc_in_data.npy\", encoder_input_data)\n",
    "np.save(\"dec_in_data.npy\", decoder_input_data)\n",
    "np.save(\"dec_out_data.npy\", decoder_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer that needs to be used in conjunction with the sequence modelso we can use it elsewhere\n",
    "with open(f'saved_models/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Conversational Based Agent.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ama",
   "language": "python",
   "name": "ama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
