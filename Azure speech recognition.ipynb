{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RKV2BEL76euo"
   },
   "source": [
    "<h1 style=\"text-align: center;text-transform: uppercase;\">Conversational Based Agent</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "In this project, you will build an end-to-end voice conversational agent, which can take a voice input audio line, and synthesize a response. The chatbot agent will be executed locally on your computer. \n",
    "\n",
    "<img style=\"width:550px; height:300px;\" src=\"assets/intro.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9fuw6EH4LOU"
   },
   "source": [
    "This jupyter notebook is consists of the following parts:\n",
    "1. __Speech Recognition:__ <br>In this part, you will create a speech recognition that can convert your voice into a text format.<br><br>\n",
    "2. __Chatbot:__ <br>This is the core of your conversational based agent. You will build a chatbot that will answer your questions. <br><br>\n",
    "3. __Text to Speech:__ <br>After getting the answer from your chatbot, it should be converted into a voice format and that is what you should create in this part. <br><br>\n",
    "4. __Finalize your Conversational Based Agent:__ <br>At the very end step, you will put everything together and create your Conversational Based Agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gx13lGaR6evT"
   },
   "source": [
    "<br>\n",
    "\n",
    "# 1. Speech Recognition\n",
    "\n",
    "---\n",
    "\n",
    "In this part, we will use <a href=\"https://azure.microsoft.com/en-us/services/cognitive-services/speech-to-text/\">Microsoft Azure</a> for performing the speech recognition. Using the Speech service is easy and affordable. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### 1.1. Create your Azure Account\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Before doing any speech recognition task, you need to follow these steps for setting up your account at Azure Microsoft:\n",
    "\n",
    "1. If you do not have a Microsoft account, you can sign up for one free of charge at the <a href=\"https://account.microsoft.com/account\">Microsoft account portal</a>. <br><br>\n",
    "\n",
    "2. Once you have a Microsoft account, go to the <a href=\"https://azure.microsoft.com/en-gb/free/ai/\">Azure sign-up page</a>, select Start free, and create a new Azure account using a Microsoft account. <br><br>\n",
    "\n",
    "3. Sign in to the <a href=\"https://portal.azure.com/\">Azure portal</a> using your Microsoft account. <br><br>\n",
    "\n",
    "4. Select Create a resource at the top left of the portal. If you do not see Create a resource, you can always find it by selecting the collapsed menu in the upper left:\n",
    "\n",
    "<img width=\"500px\" src=\"assets/collapsed-nav.png\">\n",
    "<br><br>\n",
    "\n",
    "5. In the New window, type \"speech\" in the search box and press ENTER. <br><br>\n",
    "\n",
    "6. In the search results, select Speech.\n",
    "\n",
    "<img width=\"700px\" src=\"assets/speech-search.png\">\n",
    "<br><br>\n",
    "\n",
    "7. Select Create, then:\n",
    "    - 7.1. Give a unique name for your new resource.\n",
    "    - 7.2. Choose the Azure subscription that the new resource is associated with to determine how the fees are billed.\n",
    "    - 7.3. Choose the <a href=\"https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/regions\">region</a>.\n",
    "    - 7.4. Choose either a free (F0) or paid (S0) pricing tier.\n",
    "    - 7.5. Create a new resource group for this Speech subscription or assign the subscription to an existing resource group. Resource groups help you keep your various Azure subscriptions organized.\n",
    "    - 7.6. Select Create. This will take you to the deployment overview and display deployment progress messages.\n",
    "<br><br>\n",
    "\n",
    "It takes a few moments to deploy your new Speech resource. Once deployment is complete, select __Go to resource__ and in the left navigation pane select __Keys__ to display your Speech service subscription keys. Each subscription has two keys; you can use either key in your application. To quickly copy/paste a key to your code editor or other location, select the copy button next to each key, switch windows to paste the clipboard contents to the desired location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oK-eA2LN4LOX"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 1.2. Perform the Speech Recognition Task\n",
    "\n",
    "---\n",
    "\n",
    "This section shows you how to use the Speech Service through the Speech SDK for Python. It illustrates how the SDK can be used to recognize speech from microphone input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3EZOs5x4LOX"
   },
   "source": [
    "First, set up some general items. Import the Speech SDK Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "V9MxWrjG4LOY"
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import azure.cognitiveservices.speech as speechsdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMdwAu7O4LOc"
   },
   "source": [
    "Set up the subscription info for the Speech Service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "eQBeIFSU4LOd"
   },
   "outputs": [],
   "source": [
    "# Create an instance of a speech config with specified subscription key and service region.\n",
    "speech_key, service_region = \"YourSubscriptionKey\", \"YourServiceRegion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1mvYlbk4LOf"
   },
   "source": [
    "Create an instance of a speech config with specified subscription key and service region. Replace with your own subscription key and service region (e.g., \"westus\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "KBgkSu4X4LOg"
   },
   "outputs": [],
   "source": [
    "# Create an instance of a speech config with specified subscription key and service region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5eD0dCwS4LOj"
   },
   "source": [
    "Create a recognizer with the given settings. Since no explicit audio config is specified, the default microphone will be used (make sure the audio settings are correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wdrqR4Ss4LOk"
   },
   "outputs": [],
   "source": [
    "# Creates a recognizer with the given settings\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(speech_config = speech_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQzqExEh4LOm"
   },
   "source": [
    "Starts speech recognition, and returns after a single utterance is recognized. The end of a single utterance is determined by listening for silence at the end or until a maximum of 15 seconds of audio is processed. The task returns the recognition text as result. \n",
    "\n",
    "__Note:__ Since `recognize_once()` returns only a single utterance, it is suitable only for single shot recognition like command or query. For long-running multi-utterance recognition, use `start_continuous_recognition()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cr4eSAXj4LOn",
    "outputId": "c067ded0-c57f-4e1c-c4bd-0e965949eef2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something...\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# Speech recognition for a single utterance \n",
    "print(\"Say something...\")\n",
    "result = speech_recognizer.recognize_once()\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized speech: \t Hello, how are you doing?\n"
     ]
    }
   ],
   "source": [
    "print(\"Recognized speech: \\t\", result.text)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Conversational Based Agent.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ama",
   "language": "python",
   "name": "ama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
