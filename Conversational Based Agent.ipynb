{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RKV2BEL76euo"
   },
   "source": [
    "<h1 style=\"text-align: center;text-transform: uppercase;\">Conversational Based Agent</h1>\n",
    "\n",
    "<br>\n",
    "\n",
    "In this project, you will build an end-to-end voice conversational agent, which can take a voice input audio line, and synthesize a response. The chatbot agent will be executed locally on your computer. \n",
    "\n",
    "<img width=\"600px\" src=\"assets/siri.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook is consists of the following parts:\n",
    "1. __Speech Recognition:__ <br>In this part, you will create a speech recognition that can convert your voice into a text format.<br><br>\n",
    "2. __Chatbot:__ <br>This is the core of your conversational based agent. You will build a chatbot that will answer your questions. <br><br>\n",
    "3. __Text to Speech:__ <br>After getting the answer from your chatbot, it should be converted into a voice format and that is what you should create in this part. <br><br>\n",
    "4. __Finalize your Conversational Based Agent:__ <br>At the very end step, you will put everything together and create your Conversational Based Agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gx13lGaR6evT"
   },
   "source": [
    "<br>\n",
    "\n",
    "# 1. Speech Recognition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIqinjUX6ewC"
   },
   "source": [
    "<br>\n",
    "\n",
    "# 2. Chatbot\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "In this part, you will create a deep learning based conversational agent. This agent will be able to interact with users and understand their questions. More specifically, you will start with loading the dataset, cleaning and preprocessing them, and then you will feed them into a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.1. Load and Clean the Dataset\n",
    "\n",
    "---\n",
    "\n",
    "In this project, we have provided you with multiple dataset files. Each of these files contains conversations regarding a specific topic. For example, topics about humor, food, movies, science, history, etc. You can read the description of each dataset in below:\n",
    "\n",
    "| Name of Dataset | Description |\n",
    "| :----:| :----: |\n",
    "| botprofile.yml | Personality of Your Chatbot |\n",
    "| humor.yml | Joke and Humor |\n",
    "| emotion.yml | Emotional Conversations |\n",
    "| politics.yml | Political Conversations |\n",
    "| ai.yml | General Questions about AI |\n",
    "| computers.yml | Conversations about Computer |\n",
    "| history.yml | Q&A about Historical Facts and Events |\n",
    "| psychology.yml | Psychological Conversations |\n",
    "| food.yml | Food Related Conversations. |\n",
    "| literature.yml | Conversations about Different Books, Authors, Genres |\n",
    "| money.yml | Conversations about Money, Investment, Economy |\n",
    "| trivia.yml | Conversations that Have Small Values |\n",
    "| gossip.yml | Gossipy Conversations |\n",
    "| conversations.yml | Common Conversations |\n",
    "| greetings.yml | Different Ways of Greeting |\n",
    "| sports.yml | Conversations about Sports. |\n",
    "| movies.yml | Conversation about Movies. |\n",
    "| science.yml | Conversations about Science  |\n",
    "| health.yml | Health Related Questions and Answers. |\n",
    "\n",
    "\n",
    "Feel free to modify these datasets in the way you want the chatbot to behave. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import yaml\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for loading all of the yml files\n",
    "def load_dataset():\n",
    "    \n",
    "    # Initialize empty lists for questions and answers\n",
    "    questions, answers = [], []\n",
    "    \n",
    "    # Get the list of all dataset names\n",
    "    dataset_names = glob.glob(\"dataset/*.yml\")\n",
    "    \n",
    "    # Iterate through each dataset name\n",
    "    for i_dataset_name in tqdm.tqdm(dataset_names):\n",
    "        \n",
    "        # Load the dataset\n",
    "        with open(i_dataset_name) as file:\n",
    "            greeting = yaml.load(file)[\"conversations\"]\n",
    "            \n",
    "        # Iterate through each conversation\n",
    "        for i_conversation in greeting:\n",
    "            \n",
    "            # If length is two\n",
    "            if len(i_conversation) == 2:\n",
    "                \n",
    "                # Append the question to 'questions' list\n",
    "                questions.append(i_conversation[0])\n",
    "                \n",
    "                # Append the answer to 'answers' list\n",
    "                answers.append(i_conversation[1])\n",
    "            \n",
    "            # If length is more than two\n",
    "            elif len(i_conversation) > 2:\n",
    "                \n",
    "                # Iterate through each index\n",
    "                for index in range (len(i_conversation)-1):\n",
    "                    \n",
    "                    # Append the question and answer\n",
    "                    questions.append(i_conversation[0])\n",
    "                    answers.append(i_conversation[index+1])\n",
    "                    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 38.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the questions and answers\n",
    "questions, answers = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XPDgm3I66exF"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.3. Data Preprocessing\n",
    "\n",
    "---\n",
    "\n",
    "After cleaning the dataset, you should preprocess the dataset by following the below steps:\n",
    "\n",
    "1. Lower case the text.\n",
    "2. Decontract the text (e.g. she's -> she is, they're -> they are, etc.).\n",
    "3. Remove the punctuation (e.g. !, ?, $, %, #, @, ^, etc.).\n",
    "4. Tokenization.\n",
    "5. Pad the sequences to be the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qJaF_hI6exG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import contractions\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from keras import preprocessing, utils\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6ihwP5f6exI"
   },
   "outputs": [],
   "source": [
    "# Function for preprocessing the given text\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Decontracting the text (e.g. it's -> it is)\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5513,
     "status": "ok",
     "timestamp": 1574777789192,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "YX4fxi5n6exK",
    "outputId": "c787496d-b367-444b-f00b-f64623a6726e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 869/869 [00:00<00:00, 11992.68it/s]\n",
      "100%|██████████| 869/869 [00:00<00:00, 5944.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the questions\n",
    "questions_preprocessed = []\n",
    "for i_question in tqdm(questions):\n",
    "    questions_preprocessed.append(preprocess_text(i_question))\n",
    "    \n",
    "# Preprocess the answers\n",
    "answers_preprocessed = []\n",
    "for i_answer in tqdm(answers):\n",
    "    answers_preprocessed.append(preprocess_text(i_answer))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4067,
     "status": "ok",
     "timestamp": 1574777789203,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "hQ5J_WQ36exP",
    "outputId": "5c65b699-206f-488c-e169-ad833b2db4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 0: \n",
      " have you read the communist\n",
      "\n",
      "Answer 0: \n",
      " yes  marx had made some interesting observations \n",
      "--------------------------------------------------------------------------\n",
      "Question 1: \n",
      " what is a government\n",
      "\n",
      "Answer 1: \n",
      " ideally it is a representative of the people \n",
      "--------------------------------------------------------------------------\n",
      "Question 2: \n",
      " what is greenpeace\n",
      "\n",
      "Answer 2: \n",
      " global organization promoting environmental activism \n",
      "--------------------------------------------------------------------------\n",
      "Question 3: \n",
      " what is capitalism\n",
      "\n",
      "Answer 3: \n",
      " the economic system in which all or most of the means of production and distribution  as land  factories  railroads  etc   are privately owned and operated for profit  originally under fully competitive conditions \n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the preprocessed questions and answers\n",
    "for i in range(4):\n",
    "    print(\"Question {}: \\n\".format(i), questions_preprocessed[i])\n",
    "    print(\"\")\n",
    "    print(\"Answer {}: \\n\".format(i), answers_preprocessed[i])\n",
    "    print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yPRw_ueq6ex-"
   },
   "source": [
    "After preprocessing the dataset, we should add a start tag (e.g. `<START>`) and an end tag (e.g. `<END>`) to answers. Remember that we will only add these tags to answers and not questions. This requirement is because of the Seq2Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xan8xpTC6eyC"
   },
   "outputs": [],
   "source": [
    "# Add <START> and <END> tag to each sentence\n",
    "answers = list()\n",
    "for i in range(len(answers_with_tags)):\n",
    "    answers.append('<START> ' + answers_with_tags[i] + ' <END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1574777795951,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "T-gutAKp6eyD",
    "outputId": "d3c05bca-1dfc-42c0-96f9-e618ffd44930"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START> yes, marx had made some interesting observations. <END>',\n",
       " '<START> ideally it is a representative of the people. <END>',\n",
       " '<START> global organization promoting environmental activism. <END>',\n",
       " '<START> the economic system in which all or most of the means of production and distribution, as land, factories, railroads, etc., are privately owned and operated for profit, originally under fully competitive conditions. <END>',\n",
       " '<START> an established system of political administration by which a nation, state, district, etc. is governed. <END>']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XxbjI3zBU-b1"
   },
   "source": [
    "Now it's time to tokenize our dataset. We use a class in Keras which allows us to vectorize a text corpus, by turning each text into either a sequence of integers (each integer being the index of a token in a dictionary) or into a vector where the coefficient for each token could be binary, based on word count, based on tf-idf, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1028,
     "status": "ok",
     "timestamp": 1574777799261,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "p9FnHJsA6eyF",
    "outputId": "63e5be1e-e383-4ae4-f42c-932f71b2ad67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 1975\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "\n",
    "# Fit the tokenizer to questions and answers\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "\n",
    "# Get the total vocab size\n",
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "\n",
    "print( 'VOCAB SIZE : {}'.format(VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1574777808242,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "sC6cafRA6eyI",
    "outputId": "dd90845d-b306-4392-91c3-5d96c40c5144"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(869, 22) 22\n"
     ]
    }
   ],
   "source": [
    "### encoder input data\n",
    "\n",
    "# Tokenize the questions\n",
    "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
    "\n",
    "# Get the length of longest sequence\n",
    "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
    "\n",
    "# Pad the sequences\n",
    "padded_questions = pad_sequences(tokenized_questions, maxlen=maxlen_questions, padding='post')\n",
    "\n",
    "# Convert the sequences into array\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "\n",
    "print(encoder_input_data.shape, maxlen_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1574777811221,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "1urkx83k6eyJ",
    "outputId": "e99ca45b-435d-427c-cdba-4113e633fd16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(869, 45) 45\n"
     ]
    }
   ],
   "source": [
    "### decoder input data\n",
    "\n",
    "# Tokenize the answers\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "# Get the length of longest sequence\n",
    "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
    "\n",
    "# Pad the sequences\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen=maxlen_answers, padding='post')\n",
    "\n",
    "# Convert the sequences into array\n",
    "decoder_input_data = np.array(padded_answers)\n",
    "\n",
    "print(decoder_input_data.shape, maxlen_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21910,
     "status": "ok",
     "timestamp": 1574777834510,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "hvq32nEI6eyL",
    "outputId": "7038d6d7-eeb8-4f7b-94b4-9df4b597aca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(869, 45, 1975)\n"
     ]
    }
   ],
   "source": [
    "### decoder_output_data\n",
    "\n",
    "# Tokenize the answers\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "# Iterate through index of tokenized answers\n",
    "for i in range(len(tokenized_answers)) :\n",
    "\n",
    "    #\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "\n",
    "# Pad the tokenized answers\n",
    "padded_answers = pad_sequences(tokenized_answers, maxlen = maxlen_answers, padding = 'post')\n",
    "\n",
    "# One hot encode\n",
    "onehot_answers = utils.to_categorical(padded_answers, VOCAB_SIZE)\n",
    "\n",
    "# Convert to numpy array\n",
    "decoder_output_data = np.array(onehot_answers)\n",
    "\n",
    "print(decoder_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all the arrays to storage\n",
    "np.save(\"enc_in_data.npy\", encoder_input_data)\n",
    "np.save(\"dec_in_data.npy\", decoder_input_data)\n",
    "np.save(\"dec_tar_data.npy\", decoder_output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ClM9JxbyeJ0C"
   },
   "outputs": [],
   "source": [
    "# Load all the arrays from storage\n",
    "encoder_input_data = np.load(\"enc_in_data.npy\")\n",
    "decoder_input_data = np.load(\"dec_in_data.npy\")\n",
    "decoder_output_data = np.load(\"dec_tar_data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PCTc1O_meJ0F"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.4. Train the Seq2Seq Model\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we will use an architecture called Sequence to Sequence (or Seq2Seq). This model is used since the length of the input sequence (question) does not match the length of the output sequence (answer). This model is consists of an encoder and a decoder.\n",
    "- __Encoder:__ <br> In this part of the network, we take the input data and train on it. Then we pass the last state of the recurrent layer to decoder. <br><br>\n",
    "- __Decoder:__ <br> In this part of the network, we take the last state in encoder’s last recurrent layer. Then we will use it as an initial state in decoder's first recurrent layer.\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"assets/encoder_decoder.png\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's start by importing all the necessary libraries in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w521SVsleJ0F"
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.activations import softmax\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eq9ZLFSEKmNi"
   },
   "source": [
    "Below you can play around with hyperparameters for improving the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvhvarggeJ0P"
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RL28XUCmLb93"
   },
   "source": [
    "In the following block of code, you will implement the Encoder. You can follow the below steps for creating the encoder: \n",
    "\n",
    "1.   Create an input for the Encoder.\n",
    "2.   Create an embedding layer.\n",
    "3.   Create an LSTM layer which also returns the states.\n",
    "4.   Get the hidden state (state h) and cell state (state c) inside a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2314,
     "status": "ok",
     "timestamp": 1574777843896,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "IlV38YEgeJ0Q",
    "outputId": "3e16ed44-18e5-4485-88f2-e6deba644de0"
   },
   "outputs": [],
   "source": [
    "### Encoder Input\n",
    "\n",
    "# Input for encoder\n",
    "encoder_inputs = Input(shape = (None, ))\n",
    "\n",
    "# Embedding layer\n",
    "encoder_embedding = Embedding(input_dim = VOCAB_SIZE, output_dim = 200, mask_zero = True)(encoder_inputs)\n",
    "\n",
    "# LSTM layer (that returns states in addition to output)\n",
    "encoder_outputs, state_h, state_c = LSTM(units = 200, return_state = True)(encoder_embedding)\n",
    "\n",
    "# Get the states for encoder\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svSUWa7NOlKq"
   },
   "source": [
    "After creating your encoder, it's time to implement the decoder. You can follow the below steps for implementing the decoder:\n",
    "\n",
    "1.   Create an input for the decoder.\n",
    "2.   Create an embedding layer.\n",
    "3.   Create an LSTM layer that returns states and sequences.\n",
    "4.   Create a dense layer.\n",
    "5.   Get the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UaTlPLDeJ0R"
   },
   "outputs": [],
   "source": [
    "### Decoder\n",
    "\n",
    "# Input for decoder\n",
    "decoder_inputs = Input(shape = (None,  ))\n",
    "\n",
    "# Embedding layer\n",
    "decoder_embedding = Embedding(input_dim = VOCAB_SIZE, output_dim = 200 , mask_zero = True)(decoder_inputs)\n",
    "\n",
    "# LSTM layer (that returns states and sequences as well)\n",
    "decoder_lstm = LSTM(units = 200 , return_state = True , return_sequences = True)\n",
    "\n",
    "# Get the output of LSTM layer\n",
    "decoder_outputs, _, _ = decoder_lstm(inputs = decoder_embedding, initial_state = encoder_states)\n",
    "\n",
    "# Dense layer\n",
    "decoder_dense = Dense(units = VOCAB_SIZE, activation = softmax) \n",
    "\n",
    "# Get the output of Dense layer\n",
    "output = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaOFGnnoQynS"
   },
   "source": [
    "Now that you have implemented the encoder and decoder. It's time to create your model which takes two inputs: encoder's input and decoder's input. Then it outputs the decoder's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8k0ErcMZeJ0T"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Model([encoder_inputs, decoder_inputs], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1574777850758,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "VamQBht8eJ0U",
    "outputId": "ad7fcdca-ea70-456a-93ed-412b68024b99"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = RMSprop(lr = LEARNING_RATE), loss = \"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1574777852432,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "CKrCrmA26eyQ",
    "outputId": "014c8e6f-a214-4117-eea6-42a6f7d600f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 200)    395000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 200)    395000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 200), (None, 320800      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 200),  320800      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 1975)   396975      lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,828,575\n",
      "Trainable params: 1,828,575\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1507388,
     "status": "ok",
     "timestamp": 1574784415475,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "f7v7yWGOeJ0X",
    "outputId": "54cbe724-cad1-4c89-feaa-2e82069149f4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "869/869 [==============================] - 16s 18ms/step - loss: 6.1062\n",
      "Epoch 2/50\n",
      "869/869 [==============================] - 16s 18ms/step - loss: 5.3734\n",
      "Epoch 3/50\n",
      "869/869 [==============================] - 16s 19ms/step - loss: 5.1482\n",
      "Epoch 4/50\n",
      "869/869 [==============================] - 19s 21ms/step - loss: 4.9950\n",
      "Epoch 5/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 4.8604\n",
      "Epoch 6/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 4.7477\n",
      "Epoch 7/50\n",
      "869/869 [==============================] - 16s 19ms/step - loss: 4.6162\n",
      "Epoch 8/50\n",
      "869/869 [==============================] - 19s 22ms/step - loss: 4.5043\n",
      "Epoch 9/50\n",
      "869/869 [==============================] - 14s 17ms/step - loss: 4.3848\n",
      "Epoch 10/50\n",
      "869/869 [==============================] - 16s 18ms/step - loss: 4.2659\n",
      "Epoch 11/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 4.1606\n",
      "Epoch 12/50\n",
      "869/869 [==============================] - 14s 17ms/step - loss: 4.0488\n",
      "Epoch 13/50\n",
      "869/869 [==============================] - 14s 17ms/step - loss: 3.9646\n",
      "Epoch 14/50\n",
      "869/869 [==============================] - 15s 17ms/step - loss: 3.8774\n",
      "Epoch 15/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 3.7869\n",
      "Epoch 16/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 3.6863\n",
      "Epoch 17/50\n",
      "869/869 [==============================] - 15s 17ms/step - loss: 3.6127\n",
      "Epoch 18/50\n",
      "869/869 [==============================] - 16s 18ms/step - loss: 3.5238\n",
      "Epoch 19/50\n",
      "869/869 [==============================] - 20s 23ms/step - loss: 3.4436\n",
      "Epoch 20/50\n",
      "869/869 [==============================] - 19s 21ms/step - loss: 3.3578\n",
      "Epoch 21/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 3.2719\n",
      "Epoch 22/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 3.1968\n",
      "Epoch 23/50\n",
      "869/869 [==============================] - 14s 17ms/step - loss: 3.1138\n",
      "Epoch 24/50\n",
      "869/869 [==============================] - 15s 17ms/step - loss: 3.0390\n",
      "Epoch 25/50\n",
      "869/869 [==============================] - 15s 17ms/step - loss: 2.9560\n",
      "Epoch 26/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 2.8718\n",
      "Epoch 27/50\n",
      "869/869 [==============================] - 16s 18ms/step - loss: 2.8004\n",
      "Epoch 28/50\n",
      "869/869 [==============================] - 14s 17ms/step - loss: 2.7217\n",
      "Epoch 29/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 2.6502\n",
      "Epoch 30/50\n",
      "869/869 [==============================] - 16s 18ms/step - loss: 2.5713\n",
      "Epoch 31/50\n",
      "869/869 [==============================] - 23s 26ms/step - loss: 2.4985\n",
      "Epoch 32/50\n",
      "869/869 [==============================] - 16s 19ms/step - loss: 2.4250\n",
      "Epoch 33/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 2.3547\n",
      "Epoch 34/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 2.2815\n",
      "Epoch 35/50\n",
      "869/869 [==============================] - 19s 21ms/step - loss: 2.2163\n",
      "Epoch 36/50\n",
      "869/869 [==============================] - 19s 22ms/step - loss: 2.1479\n",
      "Epoch 37/50\n",
      "869/869 [==============================] - 18s 21ms/step - loss: 2.0772\n",
      "Epoch 38/50\n",
      "869/869 [==============================] - 15s 17ms/step - loss: 2.0142\n",
      "Epoch 39/50\n",
      "869/869 [==============================] - 14s 17ms/step - loss: 1.9473\n",
      "Epoch 40/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.8832\n",
      "Epoch 41/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.8226\n",
      "Epoch 42/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.7679\n",
      "Epoch 43/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.7059\n",
      "Epoch 44/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.6442\n",
      "Epoch 45/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.5839\n",
      "Epoch 46/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.5300\n",
      "Epoch 47/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.4807\n",
      "Epoch 48/50\n",
      "869/869 [==============================] - 16s 19ms/step - loss: 1.4207\n",
      "Epoch 49/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.3721\n",
      "Epoch 50/50\n",
      "869/869 [==============================] - 14s 16ms/step - loss: 1.3221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x125fbce10>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x = [encoder_input_data , decoder_input_data], \n",
    "          y = decoder_output_data, \n",
    "          batch_size = BATCH_SIZE, \n",
    "          epochs = EPOCHS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 200) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 200) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weight Saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the final model\n",
    "model.save(filepath = './saved models/final_weight.h5') \n",
    "print(\"Model Weight Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1574784417327,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "r0ljtrcNeJ0Z",
    "outputId": "19d52267-e8e6-401e-9bc0-e2c859a1d207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weight Loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load the final model\n",
    "model.load_weights('saved models/final_weight.h5') \n",
    "print(\"Model Weight Loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F33sverZeJ0b"
   },
   "source": [
    "<br>\n",
    "\n",
    "### 3.5. Inference\n",
    "\n",
    "---\n",
    "\n",
    "Now it's time to use our model for inference. In other words, we will ask a question to our chatbot and it will answer us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaDAPDOa6eyb"
   },
   "outputs": [],
   "source": [
    "# Function for making inference\n",
    "def make_inference_models():\n",
    "    \n",
    "    # Create a model that takes encoder's input and outputs the states for encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    # Create two inputs for decoder which are hidden state (or state h) and cell state (or state c)\n",
    "    decoder_state_input_h = Input(shape = (200, ))\n",
    "    decoder_state_input_c = Input(shape = (200, ))\n",
    "    \n",
    "    # Store the two inputs for decoder inside a list\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    # Pass the inputs through LSTM layer you have created before\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state = decoder_states_inputs)\n",
    "    \n",
    "    # Store the outputted hidden state and cell state from LSTM inside a list\n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    # Pass the output from LSTM layer through the dense layer you have created before\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Create a model that takes decoder_inputs and decoder_states_inputs as inputs and outputs decoder_outputs and decoder_states\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                          [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWYFiofO6eye"
   },
   "outputs": [],
   "source": [
    "# Function for converting strings to tokens\n",
    "def str_to_tokens(sentence:str):\n",
    "\n",
    "    # Lowercase the sentence and split it into words\n",
    "    words = sentence.lower().split()\n",
    "\n",
    "    # Initialize a list for tokens\n",
    "    tokens_list = list()\n",
    "\n",
    "    # Iterate through words\n",
    "    for word in words:\n",
    "\n",
    "        # Append the word index inside tokens list\n",
    "        tokens_list.append(tokenizer.word_index[word]) \n",
    "\n",
    "    # Pad the sequences to be the same length\n",
    "    return pad_sequences([tokens_list] , maxlen = maxlen_questions, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41057,
     "status": "ok",
     "timestamp": 1574785069922,
     "user": {
      "displayName": "soheil mohammadpour",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mADGOX2Mrqnd4Kv8uSoUa349iTKp3mAzZjVlkqF=s64",
      "userId": "06946141564410396693"
     },
     "user_tz": -240
    },
    "id": "0ageXsgb6eyg",
    "outputId": "a327f8f1-97b5-4e48-8d83-42135f2b6745",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question : Hello!\n",
      " hi \n",
      "Enter question : How are you doing?\n",
      " i am doing well \n",
      "Enter question : Can i ask you a question?\n",
      " sure ask away \n",
      "Enter question : What are your interests?\n",
      " i am interested in a computer \n",
      "Enter question : Tell me a joke\n",
      " what do you get when you cross a cat and a lemon \n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for inference\n",
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "# Iterate through the number of times you want to ask question\n",
    "for _ in range(5):\n",
    "\n",
    "    # Get the input and predict it with the encoder model\n",
    "    states_values = enc_model.predict(str_to_tokens(preprocess_text(input('Enter question : '))))\n",
    "\n",
    "    # Initialize the target sequence with zero - array([[0.]])\n",
    "    empty_target_seq = np.zeros(shape = (1, 1))\n",
    "\n",
    "    # Update the target sequence with index of \"start\"\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index[\"start\"]\n",
    "\n",
    "    # Initialize the stop condition with False\n",
    "    stop_condition = False\n",
    "\n",
    "    # Initialize the decoded words with an empty string\n",
    "    decoded_translation = ''\n",
    "\n",
    "    # While stop_condition is false\n",
    "    while not stop_condition :\n",
    "\n",
    "        # Predict the (target sequence + the output from encoder model) with decoder model\n",
    "        dec_outputs , h , c = dec_model.predict([empty_target_seq] + states_values)\n",
    "\n",
    "        # Get the index for sampled word\n",
    "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "\n",
    "        # Initialize the sampled word with None\n",
    "        sampled_word = None\n",
    "\n",
    "        # Iterate through words and their indexes\n",
    "        for word, index in tokenizer.word_index.items() :\n",
    "\n",
    "            # If the index is equal to sampled word's index\n",
    "            if sampled_word_index == index :\n",
    "\n",
    "                # Add the word to the decoded string\n",
    "                decoded_translation += ' {}'.format(word)\n",
    "\n",
    "                # Update the sampled word\n",
    "                sampled_word = word\n",
    "        \n",
    "        # If sampled word is equal to \"end\" OR the length of decoded string is more that what is allowed\n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "\n",
    "            # Make the stop_condition to true\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Initialize back the target sequence to zero - array([[0.]])    \n",
    "        empty_target_seq = np.zeros(shape = (1, 1))  \n",
    "\n",
    "        # Update the target sequence with index of \"start\"\n",
    "        empty_target_seq[0, 0] = sampled_word_index\n",
    "\n",
    "        # Get the state values\n",
    "        states_values = [h, c] \n",
    "\n",
    "    # Print the decoded string\n",
    "    print(decoded_translation[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the number of times you want to ask question\n",
    "def text_to_text(input_text):\n",
    "    \n",
    "    # Initialize the model for inference\n",
    "    enc_model , dec_model = make_inference_models()\n",
    "\n",
    "    # Get the input and predict it with the encoder model\n",
    "    states_values = enc_model.predict(str_to_tokens(preprocess_text(input_text)))\n",
    "\n",
    "    # Initialize the target sequence with zero - array([[0.]])\n",
    "    empty_target_seq = np.zeros(shape = (1, 1))\n",
    "\n",
    "    # Update the target sequence with index of \"start\"\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index[\"start\"]\n",
    "\n",
    "    # Initialize the stop condition with False\n",
    "    stop_condition = False\n",
    "\n",
    "    # Initialize the decoded words with an empty string\n",
    "    decoded_translation = ''\n",
    "\n",
    "    # While stop_condition is false\n",
    "    while not stop_condition :\n",
    "\n",
    "        # Predict the (target sequence + the output from encoder model) with decoder model\n",
    "        dec_outputs , h , c = dec_model.predict([empty_target_seq] + states_values)\n",
    "\n",
    "        # Get the index for sampled word\n",
    "        sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
    "\n",
    "        # Initialize the sampled word with None\n",
    "        sampled_word = None\n",
    "\n",
    "        # Iterate through words and their indexes\n",
    "        for word, index in tokenizer.word_index.items() :\n",
    "\n",
    "            # If the index is equal to sampled word's index\n",
    "            if sampled_word_index == index :\n",
    "\n",
    "                # Add the word to the decoded string\n",
    "                decoded_translation += ' {}'.format(word)\n",
    "\n",
    "                # Update the sampled word\n",
    "                sampled_word = word\n",
    "        \n",
    "        # If sampled word is equal to \"end\" OR the length of decoded string is more that what is allowed\n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "\n",
    "            # Make the stop_condition to true\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Initialize back the target sequence to zero - array([[0.]])    \n",
    "        empty_target_seq = np.zeros(shape = (1, 1))  \n",
    "\n",
    "        # Update the target sequence with index of \"start\"\n",
    "        empty_target_seq[0, 0] = sampled_word_index\n",
    "\n",
    "        # Get the state values\n",
    "        states_values = [h, c] \n",
    "\n",
    "    # return the decoded string\n",
    "    return decoded_translation[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' i am doing well '"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_text(\"How are you doing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-z2MXSd6ezL"
   },
   "source": [
    "# 4. Text to Speech\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UOU6Y0DK6ezM"
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a new TTS engine instance\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voice 0: \n",
      " - ID: com.apple.speech.synthesis.voice.Alex\n",
      " - Name: Alex\n",
      " - Languages: ['en_US']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 1: \n",
      " - ID: com.apple.speech.synthesis.voice.alice\n",
      " - Name: Alice\n",
      " - Languages: ['it_IT']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 2: \n",
      " - ID: com.apple.speech.synthesis.voice.alva\n",
      " - Name: Alva\n",
      " - Languages: ['sv_SE']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 3: \n",
      " - ID: com.apple.speech.synthesis.voice.amelie\n",
      " - Name: Amelie\n",
      " - Languages: ['fr_CA']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 4: \n",
      " - ID: com.apple.speech.synthesis.voice.anna\n",
      " - Name: Anna\n",
      " - Languages: ['de_DE']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 5: \n",
      " - ID: com.apple.speech.synthesis.voice.carmit\n",
      " - Name: Carmit\n",
      " - Languages: ['he_IL']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 6: \n",
      " - ID: com.apple.speech.synthesis.voice.damayanti\n",
      " - Name: Damayanti\n",
      " - Languages: ['id_ID']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 7: \n",
      " - ID: com.apple.speech.synthesis.voice.daniel.premium\n",
      " - Name: Daniel\n",
      " - Languages: ['en_GB']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 8: \n",
      " - ID: com.apple.speech.synthesis.voice.diego\n",
      " - Name: Diego\n",
      " - Languages: ['es_AR']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 9: \n",
      " - ID: com.apple.speech.synthesis.voice.ellen\n",
      " - Name: Ellen\n",
      " - Languages: ['nl_BE']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 10: \n",
      " - ID: com.apple.speech.synthesis.voice.fiona\n",
      " - Name: Fiona\n",
      " - Languages: ['en-scotland']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 11: \n",
      " - ID: com.apple.speech.synthesis.voice.Fred\n",
      " - Name: Fred\n",
      " - Languages: ['en_US']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 30\n",
      "\n",
      "Voice 12: \n",
      " - ID: com.apple.speech.synthesis.voice.ioana\n",
      " - Name: Ioana\n",
      " - Languages: ['ro_RO']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 13: \n",
      " - ID: com.apple.speech.synthesis.voice.joana\n",
      " - Name: Joana\n",
      " - Languages: ['pt_PT']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 14: \n",
      " - ID: com.apple.speech.synthesis.voice.jorge\n",
      " - Name: Jorge\n",
      " - Languages: ['es_ES']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 15: \n",
      " - ID: com.apple.speech.synthesis.voice.juan\n",
      " - Name: Juan\n",
      " - Languages: ['es_MX']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 16: \n",
      " - ID: com.apple.speech.synthesis.voice.kanya\n",
      " - Name: Kanya\n",
      " - Languages: ['th_TH']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 17: \n",
      " - ID: com.apple.speech.synthesis.voice.karen\n",
      " - Name: Karen\n",
      " - Languages: ['en_AU']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 18: \n",
      " - ID: com.apple.speech.synthesis.voice.kyoko\n",
      " - Name: Kyoko\n",
      " - Languages: ['ja_JP']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 19: \n",
      " - ID: com.apple.speech.synthesis.voice.laura\n",
      " - Name: Laura\n",
      " - Languages: ['sk_SK']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 20: \n",
      " - ID: com.apple.speech.synthesis.voice.lekha\n",
      " - Name: Lekha\n",
      " - Languages: ['hi_IN']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 21: \n",
      " - ID: com.apple.speech.synthesis.voice.luca\n",
      " - Name: Luca\n",
      " - Languages: ['it_IT']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 22: \n",
      " - ID: com.apple.speech.synthesis.voice.luciana\n",
      " - Name: Luciana\n",
      " - Languages: ['pt_BR']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 23: \n",
      " - ID: com.apple.speech.synthesis.voice.maged\n",
      " - Name: Maged\n",
      " - Languages: ['ar_SA']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 24: \n",
      " - ID: com.apple.speech.synthesis.voice.mariska\n",
      " - Name: Mariska\n",
      " - Languages: ['hu_HU']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 25: \n",
      " - ID: com.apple.speech.synthesis.voice.mei-jia\n",
      " - Name: Mei-Jia\n",
      " - Languages: ['zh_TW']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 26: \n",
      " - ID: com.apple.speech.synthesis.voice.melina\n",
      " - Name: Melina\n",
      " - Languages: ['el_GR']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 27: \n",
      " - ID: com.apple.speech.synthesis.voice.milena\n",
      " - Name: Milena\n",
      " - Languages: ['ru_RU']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 28: \n",
      " - ID: com.apple.speech.synthesis.voice.moira\n",
      " - Name: Moira\n",
      " - Languages: ['en_IE']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 29: \n",
      " - ID: com.apple.speech.synthesis.voice.monica\n",
      " - Name: Monica\n",
      " - Languages: ['es_ES']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 30: \n",
      " - ID: com.apple.speech.synthesis.voice.nora\n",
      " - Name: Nora\n",
      " - Languages: ['nb_NO']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 31: \n",
      " - ID: com.apple.speech.synthesis.voice.paulina\n",
      " - Name: Paulina\n",
      " - Languages: ['es_MX']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 32: \n",
      " - ID: com.apple.speech.synthesis.voice.samantha\n",
      " - Name: Samantha\n",
      " - Languages: ['en_US']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 33: \n",
      " - ID: com.apple.speech.synthesis.voice.sara\n",
      " - Name: Sara\n",
      " - Languages: ['da_DK']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 34: \n",
      " - ID: com.apple.speech.synthesis.voice.satu\n",
      " - Name: Satu\n",
      " - Languages: ['fi_FI']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 35: \n",
      " - ID: com.apple.speech.synthesis.voice.sin-ji\n",
      " - Name: Sin-ji\n",
      " - Languages: ['zh_HK']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 36: \n",
      " - ID: com.apple.speech.synthesis.voice.tessa\n",
      " - Name: Tessa\n",
      " - Languages: ['en_ZA']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 37: \n",
      " - ID: com.apple.speech.synthesis.voice.thomas\n",
      " - Name: Thomas\n",
      " - Languages: ['fr_FR']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 38: \n",
      " - ID: com.apple.speech.synthesis.voice.ting-ting\n",
      " - Name: Ting-Ting\n",
      " - Languages: ['zh_CN']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 39: \n",
      " - ID: com.apple.speech.synthesis.voice.veena\n",
      " - Name: Veena\n",
      " - Languages: ['en_IN']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 40: \n",
      " - ID: com.apple.speech.synthesis.voice.Victoria\n",
      " - Name: Victoria\n",
      " - Languages: ['en_US']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 41: \n",
      " - ID: com.apple.speech.synthesis.voice.xander\n",
      " - Name: Xander\n",
      " - Languages: ['nl_NL']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 42: \n",
      " - ID: com.apple.speech.synthesis.voice.yelda\n",
      " - Name: Yelda\n",
      " - Languages: ['tr_TR']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 43: \n",
      " - ID: com.apple.speech.synthesis.voice.yuna\n",
      " - Name: Yuna\n",
      " - Languages: ['ko_KR']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 44: \n",
      " - ID: com.apple.speech.synthesis.voice.yuri\n",
      " - Name: Yuri\n",
      " - Languages: ['ru_RU']\n",
      " - Gender: VoiceGenderMale\n",
      " - Age: 35\n",
      "\n",
      "Voice 45: \n",
      " - ID: com.apple.speech.synthesis.voice.zosia\n",
      " - Name: Zosia\n",
      " - Languages: ['pl_PL']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n",
      "Voice 46: \n",
      " - ID: com.apple.speech.synthesis.voice.zuzana\n",
      " - Name: Zuzana\n",
      " - Languages: ['cs_CZ']\n",
      " - Gender: VoiceGenderFemale\n",
      " - Age: 35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all of the voices\n",
    "voices = engine.getProperty('voices')\n",
    "\n",
    "# Loop over voices and print their descriptions\n",
    "for index, voice in enumerate(voices):\n",
    "    print(\"Voice {}: \".format(index))\n",
    "    print(\" - ID: %s\" % voice.id)\n",
    "    print(\" - Name: %s\" % voice.name)\n",
    "    print(\" - Languages: %s\" % voice.languages)\n",
    "    print(\" - Gender: %s\" % voice.gender)\n",
    "    print(\" - Age: %s\" % voice.age)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Voice properties    \n",
    "\n",
    "# Speed percent (can go over 100)\n",
    "engine.setProperty(name = 'rate', value = 180)    \n",
    "\n",
    "# Volume 0-1\n",
    "engine.setProperty(name = 'volume', value = 0.9)\n",
    "\n",
    "# Voice ID\n",
    "en_voice_id = \"com.apple.speech.synthesis.voice.daniel.premium\"\n",
    "engine.setProperty('voice', en_voice_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text to speech\n",
    "engine.say(\"You've got mail!\")\n",
    "engine.say(\"The pyttsx3 module supports native Windows and Mac speech APIs but also supports espeak, making it the best available text-to-speech package.\")\n",
    "engine.runAndWait() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 5. Finalize your Conversational Based Agent\n",
    "\n",
    "---\n",
    "\n",
    "Now it's time to put everything together so you can do speech-to-text, text-to-text, and text-to-speech at the same time. For this, you will create a button which after pushing you can speak and your model will speck to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries \n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent():\n",
    "    button = widgets.Button(description=\"Click Here for Talking!\")\n",
    "    output = widgets.Output()\n",
    "    display(button, output)\n",
    "    def on_button_clicked(b):\n",
    "        with output:\n",
    "\n",
    "            # Speech recognition\n",
    "            text = speech_recognition_g()\n",
    "            print(\" - YOU SAID: \", text)\n",
    "\n",
    "            # Text-to-text\n",
    "            response = text_to_text(text)\n",
    "            print(\" + AGENT: \", response)\n",
    "\n",
    "            # Text to speech\n",
    "            engine.say(response)\n",
    "            engine.runAndWait() \n",
    "\n",
    "\n",
    "    button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35fb6fb905f45b388bfd20a199d57cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Click Here for Talking!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474b739b6b804a2f943dd770d9fc4657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Conversational_Based_Agent 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
